# Отчет по работе Keyword spotter

## Постановка задачи
Задача keyword spotting (обнаружение ключевых слов) заключается в автоматическом распознавании заранее заданных ключевых слов или коротких фраз в непрерывном потоке речи. Цель состоит в том, чтобы определить моменты появления конкретных слов или выражений среди общего потока звуковой информации.

Для решения дается задача многоклассовой классификации коротких аудиоотрезков. В аудиозаписях необходимо детектировать
5 различных ключевых слов и отнести запись к тому или иному ключевому слову.

Теоретический подход к решению задачи: аудиозапись разбивается на чанки с перекрытием, после чего к каждому чанку
применяется преобразования Фурье. Преобразование Фурье превращает временное представление сигнала в частотное. Таким
образом, в результате мы получаем mel-спектрограмму -- частотное представление во времени. В таком представлении
mel-спектрограммы можно обрабатывать свертками, поэтому в качестве backbone модели используются сверточные 
архитектуры.

## Исследование данных

Было проведено короткое исследование распределения данных, а также исследования распределения длины аудиозаписей в 
датасетах. Большого акцента на этой части делать не стоит. Для решения задачи подобраны хорошие датасеты. 
Дисбаланса в данных нет, распределения в тренировочной и валидационной выборках одинаковые, разброса по длине аудио нет.

![Распределение данных в тренировочном датасете](/docs/images/train_data_distribution.png)

![Распределение данных в валидационном датасете](/docs/images/validation_data_distribution.png)

![Распределение по длительности аудиозаписи](/docs/images/audio_len_distrib.png)

## Цифровая обработка

Входной сигнал обрабатывается с помощью библиотеки torchaudio. Входной сигнал представляется в виде 
mel-спектрограммы и представляет собой двумерный тензор.

## Пайплайн обучения модели

В начале данные проходят аугментацию. Из методов аугментации использовались -- добавление еблого шума и 
наложение масок (аугментированные данные сохраняются в отдельный каталог, а для их извлечения 
подготавливается специальный манифест, в котором прописаны пути как к файлам исходного датасета, так и к аугментированным данным).

Далее на данных обучается модель. В качестве backbone используется сверточная нейросеть. При обучении можно
конфигурировать множество параметров (batch_size, количество эпох, др -- см конфигурационный файл), выбор
backbone архитектуры, использовать ли при обучении сгенерированные аугментацией данные и использовать ли 
метод дистиляции.

Для автоматизированного обучения нескольких моделей -- скрипт scripts/run.sh

После обучения модель можно сконвертировать в onnx формат для запуска на инференсе на основе прописанной 
архитектуры и сохраненного чекпоинта.

Для ручной валидации предусмотрен отдельный скрипт validation.py. Он нужен для сравнительного исследования 
нескольких моделей. С помощью него можно посмотреть на classification report, который дает информацию о 
метриках классификации по каждому классу.

После проверки можно сделать предсказание на тестовых данных и заслать решение.

## Направления исследований/экспериментов

### Поиск лучшей backbone архитектуры

Основное направление исследований -- подбор наиболее удачной backbone архитектуры. В работе было исследовано несколько
архитектур сверточных нейронных сетей. При подборе слоев ориетировались на общие принципы составления сверточных 
сетей, best prsctises известных архитектур (resnet, mobilenet, etc) и ограничение на количество параметров.

Результаты по архитектурам представлены в таблице.

![Результаты работы моделей](/docs/images/model_accuracy.png)

### Тюнинг параметров цифровой обработки

Первый этап обработки данных -- цифровая обработка (формирования mel-спектрограммы). У данного этапа есть свои 
гиперпараметры (частота сэмплирования, количество mel-фильтров и т. д.). Исследование показало:

- Параметры цифровой обработки не независимы. Существуют ограничения на варьирование параметров, обусловленные физическим обоснованием обработки
- Одна и та же архитектура при разных параметрах цифровой обработки может давать разные результаты (см. график)

![Распределение по длительности аудиозаписи](/docs/images/mel_spec_parameters_tuning.png)

### Представление данных

Изначально один сэмпл данных (одна аудиозапись) представлялась трехмерным тензором (num_channels, n_mels, time_samples), 
и в случае батча данных -- четырехмерным тензором (batch_size, num_channels, n_mels, time_samples).
Однако, учитывая особенность конкретной задачи, а именно -- мы работаем исключительно с одноканальными записями,
Данные можно представить в виде двумерных тензоров -- (n_mels, time_samples), трехмерным тенхором в случае батча 
данных (batch_size, n_mels, time_samples). Исследование показало, что снижение размерности данных уменьшает количество
MAC операций.

![MAC-операции](/docs/images/MAC2_compare.png)

### Аугментация данных

Для увеличения обобщающей способности моделей была предложена идея с аугментацией данных.
К аудиозаписям возможно применить простые аугментации: шифт по времени (но это может изменить 
звучание ключевого слова), наложение маски и наложение шума. Для аугментации использовались средства пакета
torchaudio.

### Дистиляция моделей

Исследовался подход с дистиляцией моделей. Поскольку в задаче существует ограничение на 
количество параметров и вычислительных операций модели, можно использовтаь только небольшие 
модели. В таком случае, можно натренировать большие модели (Mobilenet, Resnet18) и обучить маленькую модель на ответы модели-учителя.

Методика дистиляции модели: сначала обучается большая модель и сохраняется ее чекпоинт. Затем обучаем 
ученика. В процессе тренировки ученика в прямом проходе считаем функцию потерь, как взвешанную сумму 
кросс-энторпии для меток, которые предсказал ученик и KL-дивергенцию между метками, которые предсказал ученик и метками, которые предсказал учитель.

## Результаты

- было установлено, что двумерное представление данных в итоге дает меньшее количество MAC, что позволяет использовать более жирные backbone архитектуры
- было найдено несколько backbone архитектур, которые позволяют получить довольно хорошие результаты на валидационной и публичной тестовой выборках (90-93 %)
- исследование поведения модели при применении аугментации и дистиляции не дало однозначных результатов. На валидационной выборке все модели показывают результаты 89-92 %, что сопоставимо с обычным использованием лучшей backbone архитектуры. Потенциально, модель, использующая аугментацию и дистиляцию должна иметь большую обобщающую способность и давать лучшие результаты на большом количестве данных. 

## Дальнейшая работа

- более подробно сравнить модели с дистиляцией, аугментацией и без них на лучшей backbone архитектуре
- прогнать все валидные сочетания параметров цифровой обработки и найти лучшую комбинацию (исследование не было закончено, там около 600 различных комбинаций, я прогнал около 60)
- исследовать, что будет, если применять различные loss-функции
- исследовать поведение при различных параметрах оптимизатора при обучении